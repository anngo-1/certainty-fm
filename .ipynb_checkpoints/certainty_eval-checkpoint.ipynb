{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b19d67d0-5671-4840-98a4-79b1aadb1025",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import collections\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "# # Step 1: Load the image\n",
    "# image_path = 'inference_images2/Bolivia_103757_S2Hand/certainty_arr20.npy'  # Replace with your image path\n",
    "# image_array = np.load(image_path)\n",
    "\n",
    "# # Step 2: Flatten the array\n",
    "# flattened_array = image_array.flatten()\n",
    "\n",
    "# # Step 3: Exclude 0 and 1 from the array\n",
    "# filtered_array = flattened_array[(flattened_array != 0) & (flattened_array != 1)]\n",
    "\n",
    "# # Step 4: Calculate the distribution\n",
    "# value_counts = collections.Counter(filtered_array)\n",
    "\n",
    "# # Step 5: Visualize the distribution\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(filtered_array, bins=50, color='blue', edgecolor='black')\n",
    "# plt.title('Distribution of Non-zero and Non-one Values')\n",
    "# plt.xlabel('Value')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.grid(True)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63e866b-8783-4207-9a30-e6a35d13532e",
   "metadata": {},
   "source": [
    "To calculate calibration, we have to calculate per-percentage y, the rate, x at which y-certain pixels are correct. If x is extremely close to y, the certainty estimation is well calibrated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "a134f66c-6972-4c8d-94ff-4349b5b77896",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (62,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[62], line 57\u001b[0m\n\u001b[1;32m     54\u001b[0m     prob_preds\u001b[38;5;241m.\u001b[39mappend(prob_pred)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Compute the mean calibration curve\u001b[39;00m\n\u001b[0;32m---> 57\u001b[0m mean_prob_true \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprob_trues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m mean_prob_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(prob_preds, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Plot the mean calibration curve\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/numpy/core/fromnumeric.py:3504\u001b[0m, in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3501\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3502\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis\u001b[38;5;241m=\u001b[39maxis, dtype\u001b[38;5;241m=\u001b[39mdtype, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 3504\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3505\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/numpy/core/_methods.py:102\u001b[0m, in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_mean\u001b[39m(a, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, where\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 102\u001b[0m     arr \u001b[38;5;241m=\u001b[39m asanyarray(a)\n\u001b[1;32m    104\u001b[0m     is_float16_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    106\u001b[0m     rcount \u001b[38;5;241m=\u001b[39m _count_reduce_items(arr, axis, keepdims\u001b[38;5;241m=\u001b[39mkeepdims, where\u001b[38;5;241m=\u001b[39mwhere)\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (62,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "def compute_ece(prob_trues, prob_preds, n_bins):\n",
    "    ece = 0.0\n",
    "    total_samples = sum(len(prob_true) for prob_true in prob_trues)\n",
    "    \n",
    "    for i in range(len(prob_trues)):\n",
    "        bin_size = len(prob_trues[i])\n",
    "        bin_weight = bin_size / total_samples\n",
    "        abs_diff = np.abs(prob_trues[i] - prob_preds[i])\n",
    "        ece += bin_weight * np.sum(abs_diff) / n_bins\n",
    "    \n",
    "    return ece\n",
    "\n",
    "n_montecarlo = 20\n",
    "n_bins = 10\n",
    "directory = \"inference_images3\"\n",
    "\n",
    "prob_trues = []\n",
    "prob_preds = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename == \".ipynb_checkpoints\":\n",
    "        continue\n",
    "\n",
    "    imgname = filename.split(\"_\")\n",
    "    filepath = os.path.join(directory, filename)\n",
    "\n",
    "    gt_arr = np.load(f\"{filepath}/groundtruth_arr{n_montecarlo}.npy\", dtype=\"object\")\n",
    "    certainty_pred = np.load(f\"{filepath}/certainty_arr{n_montecarlo}.npy\", dtype=\"object\")\n",
    "    \n",
    "    # Replace NaN values with 0\n",
    "    gt_arr = np.nan_to_num(gt_arr, nan=0)\n",
    "    certainty_pred = np.nan_to_num(certainty_pred, nan=0)\n",
    "    \n",
    "    gt_arr = np.where(gt_arr == -1, 0, gt_arr)\n",
    "\n",
    "    # Flatten arrays\n",
    "    gt_arr = gt_arr.flatten()\n",
    "    certainty_pred = certainty_pred.flatten()\n",
    "\n",
    "    # Compute calibration curve for the current image\n",
    "    prob_true, prob_pred = calibration_curve(gt_arr, certainty_pred, n_bins=n_bins)\n",
    "    \n",
    "    # Check shapes\n",
    "    if len(prob_true) != len(prob_pred):\n",
    "        print(f\"Warning: Different lengths of prob_true ({len(prob_true)}) and prob_pred ({len(prob_pred)}) for file {filename}\")\n",
    "\n",
    "    # Append to lists\n",
    "    prob_trues.append(prob_true)\n",
    "    prob_preds.append(prob_pred)\n",
    "\n",
    "# Compute the mean calibration curve\n",
    "mean_prob_true = np.mean(prob_trues, axis=0)\n",
    "mean_prob_pred = np.mean(prob_preds, axis=0)\n",
    "\n",
    "# Plot the mean calibration curve\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(mean_prob_pred, mean_prob_true, marker='o', label='Mean Calibration curve')\n",
    "\n",
    "# Plot the perfect calibration line\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', label='Perfectly calibrated')\n",
    "\n",
    "plt.xlabel('Mean predicted probability')\n",
    "plt.ylabel('Fraction of positives')\n",
    "plt.title('Mean Calibration Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Calculate ECE\n",
    "ece = compute_ece(prob_trues, prob_preds, n_bins=n_bins)\n",
    "print(f'Expected Calibration Error (ECE): {ece:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24daa49-61f8-427a-a7c3-6da8adf891a8",
   "metadata": {},
   "source": [
    "We combine our certainty estimation (variance array) with our original prediction to generate a 3 different predictions: more strict, more free, and regular.\n",
    "\n",
    "We evaluate these composites on ground truth data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc76226-491f-4fb9-a14d-2f5796da0167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turning pixels with 80th percentile+ variance to no flood pixels. Expected Result: A more conservative prediction, better F1 score\n",
    "# (good precision AND good recall) --> model gets positives right, and does not have too many false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc3b34d-f66a-4055-a732-93046c9f9151",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_montecarlo = 20\n",
    "n_bins = 10\n",
    "directory = \"inference_images2\"\n",
    "test_res = {}\n",
    "prob_trues = []\n",
    "prob_preds = []\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    if filename == \".ipynb_checkpoints\":\n",
    "        continue\n",
    "\n",
    "    imgname = filename.split(\"_\")\n",
    "    filepath = os.path.join(directory, filename)\n",
    "\n",
    "    gt_arr = np.load(f\"{filepath}/groundtruth_arr{n_montecarlo}.npy\")\n",
    "    orig_pred = np.load(f\"{filepath}/original_pred{n_montecarlo}.npy\")\n",
    "    var_pred = np.load(f\"{filepath}/variance_arr{n_montecarlo}.npy\")\n",
    "\n",
    "    gt_arr.flatten()\n",
    "    orig_pred.flatten()\n",
    "    var_pred.flatten()\n",
    "\n",
    "    threshold = np.percentile(var_pred, 80)\n",
    "\n",
    "    var_pred = np.where(var_pred >= threshold, 1, 0)\n",
    "    gt_arr = np.where(gt_arr == -1, 0, gt_arr)\n",
    "\n",
    "\n",
    "\n",
    "    composite_pred = orig_pred * var_pred\n",
    "\n",
    "    test_res[filename] = [f1_score(gt_arr, orig_pred), f1_score(gt_arr, composite_pred), f1_score(gt_arr, composite_pred) - f1_score(gt_arr, orig_pred)]\n",
    "\n",
    "    # if np.sum(gt_arr == 1) < 500:\n",
    "    #     continue\n",
    "\n",
    "    # gt_arr = gt_arr.flatten()\n",
    "    # orig_pred = orig_pred.flatten()\n",
    "\n",
    "print(test_res)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
